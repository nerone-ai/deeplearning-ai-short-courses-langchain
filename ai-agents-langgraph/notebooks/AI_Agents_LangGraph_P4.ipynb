{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a703a6ec",
   "metadata": {},
   "source": [
    "# AI Agents in LangGraph – Lesson 4\n",
    "\n",
    "**Objective**: Explore the concepts of persistence and streaming in LangGraph to enable long-running agents with persistent memory and real-time streaming output.\n",
    "\n",
    "LangGraph supports:\n",
    "- ✅ **Persistence**: Save and resume conversation state using a checkpointer.\n",
    "- ✅ **Streaming**: View intermediate reasoning steps and token-level output in real-time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058cc05a",
   "metadata": {},
   "source": [
    "## 1. Setup: Imports, API Keys, and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "540decee",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "# !pip install -q langchain langgraph tavily-python aiosqlite\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import operator\n",
    "from typing import TypedDict, Annotated\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Load environment variables for Tavily search tool\n",
    "load_dotenv()\n",
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3bbe6",
   "metadata": {},
   "source": [
    "## 2. Defining Persistent Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb02233e",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Define the state of the agent - annotate the messages list to enable persistence\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac2c29",
   "metadata": {},
   "source": [
    "## 3. Defining the Agent with Persistence Support\n",
    "\n",
    "In order to define the agent with persistence support, the concept of checkpointer has been introduced. Checkpointer is a function that takes the state of the agent and returns a string that can be used to restore the state of the agent, for example to continue a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15153bc6",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# Define memory as a checkpointer to persist the state of the agent\n",
    "\n",
    "# In-memory SQLite checkpointer\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c964a07",
   "metadata": {
    "height": 591
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# Define the agent class with additional checkpointing support\n",
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"): # added ckeckpointer as input\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        # only modification is to pass the checkpointer to the graph\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        return {\"messages\": [self.model.invoke(messages)]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cdb303",
   "metadata": {},
   "source": [
    "## 4. Using the Agent with Persistent Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8605ec",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "# Define the agent with prompt, model and checkpointer as the memory defined above\n",
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\"\"\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "# only modification is to add checkpointer to the agent\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461dfbbc",
   "metadata": {},
   "source": [
    "## 5. Streaming Messages with Persistent Context\n",
    "\n",
    "A key concept is streaming, both of individual messages or of output tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdac4728",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cCD4LJhJTCk8IAnBuFJTVQnH', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 151, 'total_tokens': 174, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_90122d973c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5c370c9b-2a23-4d83-8c55-a16d19815fbc-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_cCD4LJhJTCk8IAnBuFJTVQnH'}])]\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://weathershogun.com/weather/usa/ca/san-francisco/480/may/2025-05-09\\', \\'content\\': \\'San Francisco, California Weather: Friday, May 9, 2025. Cloudy weather, overcast skies with clouds. Day 61°. Night 50°. Precipitation 0 %.\\'}, {\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1746799405, \\'localtime\\': \\'2025-05-09 07:03\\'}, \\'current\\': {\\'last_updated_epoch\\': 1746799200, \\'last_updated\\': \\'2025-05-09 07:00\\', \\'temp_c\\': 11.1, \\'temp_f\\': 52.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Fog\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/248.png\\', \\'code\\': 1135}, \\'wind_mph\\': 2.2, \\'wind_kph\\': 3.6, \\'wind_degree\\': 233, \\'wind_dir\\': \\'SW\\', \\'pressure_mb\\': 1018.0, \\'pressure_in\\': 30.07, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 93, \\'cloud\\': 25, \\'feelslike_c\\': 11.5, \\'feelslike_f\\': 52.6, \\'windchill_c\\': 7.5, \\'windchill_f\\': 45.5, \\'heatindex_c\\': 8.0, \\'heatindex_f\\': 46.5, \\'dewpoint_c\\': 8.2, \\'dewpoint_f\\': 46.7, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.2, \\'gust_mph\\': 3.1, \\'gust_kph\\': 5.0}}\"}]', name='tavily_search_results_json', tool_call_id='call_cCD4LJhJTCk8IAnBuFJTVQnH')]\n",
      "[AIMessage(content='The current weather in San Francisco is foggy. The temperature is 52°F (11.1°C) with a feels-like temperature of 52.6°F (11.5°C). The humidity is high at 93%, and there is a slight wind coming from the southwest at 2.2 mph (3.6 kph). Visibility is about 9 miles (16 km), and there is no precipitation expected.', response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 668, 'total_tokens': 757, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_90122d973c', 'finish_reason': 'stop', 'logprobs': None}, id='run-88afbe84-015b-41f0-a399-f6dee0165df7-0')]\n"
     ]
    }
   ],
   "source": [
    "# Example of streaming individual messages\n",
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "# Definition of thread configuration to keep track of different threads,\n",
    "# for example allowing multiple conversations\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Call the graph with the messages and thread and .stream not .invoke as before\n",
    "# loop over a stream of events and print the messages\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b7bcb9",
   "metadata": {
    "height": 30
   },
   "source": [
    "The output include: AIMessage which is output of the LLM with the tool call, TooMessage which is the output of the search tool, and finally AIMessage which is the final LLM output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6d55c",
   "metadata": {},
   "source": [
    "### Follow-up: Asking a question in the same thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be1909b",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mXS0smAXFFHNAeiMLmZ4CA8p', 'function': {'arguments': '{\"query\":\"current weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 768, 'total_tokens': 791, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_90122d973c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-736bfccf-e035-4c8f-963c-2b05a2d05416-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_mXS0smAXFFHNAeiMLmZ4CA8p'}])]}\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://weathershogun.com/weather/usa/ca/los-angeles/451/may/2025-05-09\\', \\'content\\': \\'Los Angeles, California Weather: Friday, May 9, 2025. Cloudy weather, overcast skies with clouds. Day 90°. Night 64°. Precipitation 0 %.\\'}, {\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.0522, \\'lon\\': -118.2428, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1746799263, \\'localtime\\': \\'2025-05-09 07:01\\'}, \\'current\\': {\\'last_updated_epoch\\': 1746799200, \\'last_updated\\': \\'2025-05-09 07:00\\', \\'temp_c\\': 14.4, \\'temp_f\\': 57.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 2.2, \\'wind_kph\\': 3.6, \\'wind_degree\\': 183, \\'wind_dir\\': \\'S\\', \\'pressure_mb\\': 1017.0, \\'pressure_in\\': 30.02, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 93, \\'cloud\\': 60, \\'feelslike_c\\': 15.1, \\'feelslike_f\\': 59.2, \\'windchill_c\\': 17.1, \\'windchill_f\\': 62.8, \\'heatindex_c\\': 17.1, \\'heatindex_f\\': 62.8, \\'dewpoint_c\\': 13.7, \\'dewpoint_f\\': 56.6, \\'vis_km\\': 1.2, \\'vis_miles\\': 0.0, \\'uv\\': 0.3, \\'gust_mph\\': 2.6, \\'gust_kph\\': 4.2}}\"}]', name='tavily_search_results_json', tool_call_id='call_mXS0smAXFFHNAeiMLmZ4CA8p')]}\n",
      "{'messages': [AIMessage(content='The current weather in Los Angeles is misty. The temperature is 57.9°F (14.4°C) with a feels-like temperature of 59.2°F (15.1°C). The humidity is high at 93%, and there is a light wind coming from the south at 2.2 mph (3.6 kph). Visibility is low at about 0.7 miles (1.2 km), and there is no precipitation expected.', response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 1285, 'total_tokens': 1382, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_90122d973c', 'finish_reason': 'stop', 'logprobs': None}, id='run-8d7c72a0-9ca9-49a4-a1e0-99b1d09f1c14-0')]}\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question without specifying the weather explicitly: the agent remembers the previous conversation\n",
    "messages = [HumanMessage(content=\"What about in LA?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fddc00e",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Currently, Los Angeles is warmer than San Francisco. The temperature in Los Angeles is 57.9°F (14.4°C), whereas in San Francisco, it is 52°F (11.1°C).', response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 1393, 'total_tokens': 1438, 'prompt_tokens_details': {'cached_tokens': 1280, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_90122d973c', 'finish_reason': 'stop', 'logprobs': None}, id='run-29cd55fd-5159-454c-a728-0713a985f3b0-0')]}\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question on the same thread: the agent has access to all the previous messages\n",
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb07183",
   "metadata": {},
   "source": [
    "### Changing Thread ID: No Memory Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b64c0695",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Could you please provide more context or specify the locations, regions, or objects you are comparing in terms of warmth?', response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 149, 'total_tokens': 174, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_90122d973c', 'finish_reason': 'stop', 'logprobs': None}, id='run-e0aa1f16-5777-406d-9c2e-38fa9ddd144e-0')]}\n"
     ]
    }
   ],
   "source": [
    "# Change the thread ID to a new value: the agent has no memory of the previous conversation\n",
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f342c",
   "metadata": {},
   "source": [
    "## 6. Streaming Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb86762",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from langchain_core._api.beta_decorator import LangChainBetaWarning\n",
    "\n",
    "# Ignore only this specific beta warning - beta feature for streaming\n",
    "warnings.filterwarnings(\"ignore\", category=LangChainBetaWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8a07606",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "# Create a memory for the agent with AsyncSqliteSaver\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "# Create the agent with checkpointer\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97697f6f",
   "metadata": {
    "height": 268
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The| current| weather| in| San| Francisco| is| fog|gy| with| a| temperature| of| |11|.|1|°C| (|52|°F|).| The| wind| is| coming| from| the| southwest| at| |2|.|2| mph| (|3|.|6| k|ph|),| and| the| humidity| is| |93|%.| The| visibility| is| |16| km| (|9| miles|).|"
     ]
    }
   ],
   "source": [
    "# Define human message\n",
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "# Create a thread with new id 4 to start conversation from scratch\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Stream events\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9411a70d",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "\n",
    "import asyncio\n",
    "\n",
    "# Define a function to stream tokens\n",
    "async def stream_tokens():\n",
    "    messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "    # Create a thread with new id 4 to start conversation from scratch\n",
    "    thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "    # Stream events\n",
    "    async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "        if event[\"event\"] == \"on_chat_model_stream\":\n",
    "            content = event[\"data\"][\"chunk\"].content\n",
    "            if content:\n",
    "                print(content, end=\"|\") # the pipe can be removed for production \n",
    "\n",
    "# To run: uncomment below line in a full async-capable environment\n",
    "# asyncio.run(stream_tokens())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c945b90",
   "metadata": {},
   "source": [
    "## ✅ Summary\n",
    "- **Checkpointer** lets your agent pause/resume conversations.\n",
    "- **Thread ID** scopes the conversation history.\n",
    "- **Streaming** shows live updates—either full messages or token-by-token.\n",
    "\n",
    "Persistence is also very important for human-in-the-loop interactions (subject to next lesson)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
